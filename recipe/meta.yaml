{% set name = "metadata-crawler" %}
{% set version = "2509.0.1" %}
{% set python_min = 3.11 %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/metadata_crawler-{{ version }}.tar.gz
  sha256: 86f688079e155e14b0605d7e6fd885417604894b30389ae668df05c226659c7d

build:
  entry_points:
    - metadata-crawler = metadata_crawler.cli:cli
    - mdc = metadata_crawler.cli:cli
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - flit-core >=3.2
    - pip
  run:
    - python >={{ python_min }}
    - aiohttp
    - appdirs
    - anyio
    - ciso8601
    - fsspec
    - diskcache
    - s3fs
    - jinja2
    - intake
    - intake-xarray
    - intake-esm
    - pandas
    - python-dateutil
    - numpy
    - orjson
    - pyarrow
    - h5netcdf
    - pydantic
    - rich
    - rich-argparse
    - tomli
    - tomlkit
    - typing_extensions
    - zarr
    - xarray
    - httpx
    - uvloop
    - motor

test:
  imports:
    - metadata_crawler
  commands:
    - pip check
    - metadata-crawler --help
    - mdc --help
  requires:
    - pip

about:
  summary: Crawl, extract and push climate metadata for indexing.
  dev_url: https://github.com/freva-org/metadata-crawler
  home: https://github.com/freva-org/metadata-crawler
  description: |
    Harvest, normalise, and index climate / earth-system metadata from **POSIX**,
    **S3/MinIO**, and **OpenStack Swift** using configurable **DRS dialects**
    (CMIP6, CMIP5, CORDEX, â€¦). Output to a temporary **catalogue** (JSONLines)
    and then **index** into systems such as **Solr** or **MongoDB**.
    Configuration is **TOML** with inheritance, templating, and computed rules.
  license: BSD-3-Clause
  license_file: LICENSE

extra:
  recipe-maintainers:
    - antarcticrainforest
